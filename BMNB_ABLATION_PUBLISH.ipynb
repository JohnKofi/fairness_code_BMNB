{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4dfba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blended_only': {'acc': 0.6697163769441903, 'fairness': {'EOD': -0.03295188012426081, 'EMOD': 0.0006703922050274314, 'SPD': 0.13256528481568633, 'DI': 1.685746590144695, 'BI': 0.2129835368224174, 'FS': 0.7870164631775826}}, 'threshold_only': {'acc': 0.7156907593778591, 'fairness': {'EOD': -0.22541425378037538, 'EMOD': -0.14405244411692458, 'SPD': 5.2568162230981486e-06, 'DI': 1.000012789660569, 'BI': 0.09237118609352303, 'FS': 0.907628813906477}}, 'full_bmnb': {'acc': 0.7143183897529735, 'fairness': {'EOD': -0.21732800041110323, 'EMOD': -0.1481285310734463, 'SPD': 5.2568162230981486e-06, 'DI': 1.000012789660569, 'BI': 0.09136864449033542, 'FS': 0.9086313555096646}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. DATA PREPROCESSING\n",
    "# =====================================================\n",
    "def preprocess_data(df, dataset_name):\n",
    "    df = df.copy()\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    if dataset_name == 'adult':\n",
    "        df.replace(\"?\", np.nan, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df[\"income\"] = df[\"income\"].apply(lambda x: 1 if \">50K\" in x else 0)\n",
    "\n",
    "        y = df[\"income\"].values\n",
    "        s = df[\"sex\"].apply(lambda x: 1 if x.strip() == \"Male\" else 0).values\n",
    "        df.drop([\"income\", \"sex\"], axis=1, inplace=True)\n",
    "\n",
    "    elif dataset_name == \"propublica\":\n",
    "        y = df[\"Two_yr_Recidivism\"].values\n",
    "        s = df[\"African_American\"].values\n",
    "\n",
    "        race_columns = [\"African_American\", \"Asian\", \"Hispanic\", \"Native_American\", \"Other\"]\n",
    "        df.drop([\"Two_yr_Recidivism\"] + race_columns, axis=1, inplace=True)\n",
    "\n",
    "    elif dataset_name == \"framingham\":\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        y = df[\"TenYearCHD\"].values\n",
    "        s = df[\"male\"].values\n",
    "        df.drop([\"TenYearCHD\", \"male\"], axis=1, inplace=True)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\" or isinstance(df[col].iloc[0], str):\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "    X = df.values\n",
    "    return X, y, s\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. BMNB MODEL CLASS\n",
    "# =====================================================\n",
    "class BMNB:\n",
    "    def __init__(self, alpha=0.5, class_priors=[0.5, 0.5]):\n",
    "        self.alpha = alpha\n",
    "        self.class_priors = class_priors\n",
    "        self.global_model = GaussianNB(priors=self.class_priors)\n",
    "        self.group_models = {}\n",
    "        self.thresholds = {}\n",
    "\n",
    "    def fit(self, X, y, s):\n",
    "        self.groups = np.unique(s)\n",
    "\n",
    "        # Global NB model\n",
    "        self.global_model.fit(X, y)\n",
    "\n",
    "        # Group-specific NB models\n",
    "        for g in self.groups:\n",
    "            idx = (s == g)\n",
    "            g_model = GaussianNB(priors=self.class_priors)\n",
    "            g_model.fit(X[idx], y[idx])\n",
    "            self.group_models[g] = g_model\n",
    "\n",
    "    def predict_proba_blended(self, X, s):\n",
    "        global_probs = self.global_model.predict_proba(X)[:, 1]\n",
    "        blended = np.zeros(len(X))\n",
    "\n",
    "        for g in self.groups:\n",
    "            idx = (s == g)\n",
    "            g_probs = self.group_models[g].predict_proba(X[idx])[:, 1]\n",
    "            blended[idx] = self.alpha * global_probs[idx] + (1 - self.alpha) * g_probs\n",
    "\n",
    "        return blended\n",
    "\n",
    "    def calibrate_thresholds(self, y_true, probs, s):\n",
    "        self.thresholds = {}\n",
    "        target_rate = np.mean(y_true)\n",
    "\n",
    "        for g in self.groups:\n",
    "            g_probs = probs[s == g]\n",
    "            if len(g_probs) == 0:\n",
    "                self.thresholds[g] = 0.5\n",
    "                continue\n",
    "\n",
    "            sorted_probs = np.sort(g_probs)\n",
    "            idx = int((1 - target_rate) * len(sorted_probs))\n",
    "            self.thresholds[g] = sorted_probs[-idx] if idx > 0 else 1.0\n",
    "\n",
    "    def predict_with_thresholds(self, probs, s):\n",
    "        preds = np.zeros_like(probs, dtype=int)\n",
    "\n",
    "        for g in self.groups:\n",
    "            idx = (s == g)\n",
    "            preds[idx] = (probs[idx] >= self.thresholds[g]).astype(int)\n",
    "\n",
    "        return preds\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. EVALUATION HELPERS\n",
    "# =====================================================\n",
    "def compute_metrics(y_test, y_pred, s_test):\n",
    "    groups = np.unique(s_test)\n",
    "    metrics = {}\n",
    "\n",
    "    for g in groups:\n",
    "        idx = (s_test == g)\n",
    "        yt, yp = y_test[idx], y_pred[idx]\n",
    "\n",
    "        TP = np.sum((yt == 1) & (yp == 1))\n",
    "        TN = np.sum((yt == 0) & (yp == 0))\n",
    "        FP = np.sum((yt == 0) & (yp == 1))\n",
    "        FN = np.sum((yt == 1) & (yp == 0))\n",
    "\n",
    "        TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "        PPR = np.mean(yp)\n",
    "\n",
    "        metrics[g] = {\"TPR\": TPR, \"FPR\": FPR, \"PPR\": PPR}\n",
    "\n",
    "    g0, g1 = metrics[0], metrics[1]\n",
    "\n",
    "    EOD = g1[\"TPR\"] - g0[\"TPR\"]\n",
    "    EMOD = g1[\"FPR\"] - g0[\"FPR\"]\n",
    "    SPD = g1[\"PPR\"] - g0[\"PPR\"]\n",
    "    DI = g1[\"PPR\"] / g0[\"PPR\"] if g0[\"PPR\"] > 0 else 0\n",
    "\n",
    "    BI = (abs(EOD) + abs(EMOD) + abs(SPD) + abs(1 - DI)) / 4\n",
    "    FS = 1 - BI\n",
    "\n",
    "    return {\n",
    "        \"EOD\": EOD, \"EMOD\": EMOD, \"SPD\": SPD, \"DI\": DI,\n",
    "        \"BI\": BI, \"FS\": FS\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. ABLATION STUDY RUNNER\n",
    "# =====================================================\n",
    "def run_ablation(X, y, s, dataset_name, alpha=0.5):\n",
    "    # STEP 1: SMOTEENN\n",
    "    sm = SMOTEENN(random_state=42)\n",
    "    X_r, y_r = sm.fit_resample(X, y)\n",
    "\n",
    "    # STEP 2: Nearest Neighbor match sensitive attribute\n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(X)\n",
    "    _, idx = nn.kneighbors(X_r)\n",
    "    s_r = s[idx.flatten()]\n",
    "\n",
    "    # STEP 3: Train-test split\n",
    "    X_train, X_test, y_train, y_test, s_train, s_test = train_test_split(\n",
    "        X_r, y_r, s_r, test_size=0.2, random_state=42, stratify=y_r\n",
    "    )\n",
    "\n",
    "    #  =============================\n",
    "    #  ABLATION 1: BLENDED ONLY\n",
    "    #  =============================\n",
    "    model1 = BMNB(alpha=alpha)\n",
    "    model1.fit(X_train, y_train, s_train)\n",
    "    probs1 = model1.predict_proba_blended(X_test, s_test)\n",
    "    y_pred1 = (probs1 >= 0.5).astype(int)\n",
    "\n",
    "    #  =============================\n",
    "    #  ABLATION 2: THRESHOLD ONLY\n",
    "    #  =============================\n",
    "    model2 = BMNB(alpha=0)   # NO blending, use global model only\n",
    "    model2.fit(X_train, y_train, s_train)\n",
    "    probs2 = model2.global_model.predict_proba(X_test)[:, 1]\n",
    "    model2.calibrate_thresholds(y_test, probs2, s_test)\n",
    "    y_pred2 = model2.predict_with_thresholds(probs2, s_test)\n",
    "\n",
    "    #  =============================\n",
    "    #  FULL BMNB (BLENDING + THRESHOLDING)\n",
    "    #  =============================\n",
    "    model3 = BMNB(alpha=alpha)\n",
    "    model3.fit(X_train, y_train, s_train)\n",
    "    probs3 = model3.predict_proba_blended(X_test, s_test)\n",
    "    model3.calibrate_thresholds(y_test, probs3, s_test)\n",
    "    y_pred3 = model3.predict_with_thresholds(probs3, s_test)\n",
    "\n",
    "    # PACKAGE RESULTS\n",
    "    results = {\n",
    "        \"blended_only\": {\n",
    "            \"acc\": accuracy_score(y_test, y_pred1),\n",
    "            \"fairness\": compute_metrics(y_test, y_pred1, s_test),\n",
    "        },\n",
    "        \"threshold_only\": {\n",
    "            \"acc\": accuracy_score(y_test, y_pred2),\n",
    "            \"fairness\": compute_metrics(y_test, y_pred2, s_test),\n",
    "        },\n",
    "        \"full_bmnb\": {\n",
    "            \"acc\": accuracy_score(y_test, y_pred3),\n",
    "            \"fairness\": compute_metrics(y_test, y_pred3, s_test),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. RUN FOR A DATASET\n",
    "# =====================================================\n",
    "# Example:\n",
    "# df = pd.read_csv(\"adult.csv\")\n",
    "# X, y, s = preprocess_data(df, \"adult\")\n",
    "# results = run_ablation(X, y, s, \"adult\")\n",
    "# print(results)\n",
    "\n",
    "# framingham_df = pd.read_csv(\"framingham.csv\")\n",
    "# X, y, s = preprocess_data(framingham_df, 'framingham')\n",
    "# results = run_ablation(X, y, s, 'framingham')\n",
    "# print(results)\n",
    "\n",
    "# propublica_df = pd.read_csv(\"propublica_data_for_fairml.csv\")\n",
    "# X, y, s = preprocess_data(propublica_df, 'propublica')\n",
    "# results = run_ablation(X, y, s, 'propublica')\n",
    "# print(results)\n",
    "\n",
    "\n",
    "adult_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Load and assign column names\n",
    "adult_df = pd.read_csv(adult_url, header=None, names=column_names, skipinitialspace=True)\n",
    "X, y, s = preprocess_data(adult_df, \"adult\")\n",
    "results = run_ablation(X, y, s, 'adult')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58c958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fb3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
